{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4Mkm5w7A5REIDoBzPM4sY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hyrule-coder/langchain-book-learning/blob/main/chapter9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LangGraphで作るAIエージェント実践入門"
      ],
      "metadata": {
        "id": "wvmEyB90b2K3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 ハンズオン: Q&Aアプリケーション"
      ],
      "metadata": {
        "id": "1k8dcB8jb4Hl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LangChainとLangGraphのインストール"
      ],
      "metadata": {
        "id": "sqBwAEEycX_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7crrh7DQb-kF",
        "outputId": "85f9b581-d59f-4b27-ca8f-fad971da9f44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.0\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-openai==0.2.0\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph==0.2.22\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (0.3.5)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.0) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.0)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting langgraph-checkpoint<2.0.0,>=1.0.2 (from langgraph==0.2.22)\n",
            "  Downloading langgraph_checkpoint-1.0.12-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.12.2)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint<2.0.0,>=1.0.2->langgraph==0.2.22) (1.1.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-1.0.12-py3-none-any.whl (17 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, tiktoken, langsmith, langgraph-checkpoint, langchain-openai, langgraph, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.2\n",
            "    Uninstalling langsmith-0.3.2:\n",
            "      Successfully uninstalled langsmith-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.16\n",
            "    Uninstalling langchain-0.3.16:\n",
            "      Successfully uninstalled langchain-0.3.16\n",
            "Successfully installed langchain-0.3.0 langchain-openai-0.2.0 langgraph-0.2.22 langgraph-checkpoint-1.0.12 langsmith-0.1.147 tenacity-8.5.0 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### OpenAI APIキーの設定"
      ],
      "metadata": {
        "id": "8xm7g-SecgUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ],
      "metadata": {
        "id": "nCDDVZdJcGfy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ロールの定義"
      ],
      "metadata": {
        "id": "1mjb4tlCckP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ROLES = {\n",
        "    \"1\": {\n",
        "        \"name\":\"一般知識エキスパート\",\n",
        "        \"description\":\"幅広い分野の一般的な質問に答える\",\n",
        "        \"details\":\"幅広い分野の一般的な質問に対して、性格でわかり易い回答を提供してください。\"\n",
        "    },\n",
        "    \"2\": {\n",
        "        \"name\":\"生成AI製品エキスパート\",\n",
        "        \"description\": \"生成AIや関連製品、技術に関する専門的な質問に答える\",\n",
        "        \"details\":\"生成AIや関連製品、技術に関する専門的な質問に対して、最新の情報と深い洞察を提供してください\"\n",
        "    },\n",
        "    \"3\": {\n",
        "        \"name\":\"カウンセラー\",\n",
        "        \"description\":\"個人的な悩みや心理的な問題に対してサポートを提供する\",\n",
        "        \"details\":\"個人的な悩みや心理的な問題に対して、共感的で支援的な回答を提供し、可能であれば適切なアドバイスも行ってください。\"\n",
        "    }\n",
        "}"
      ],
      "metadata": {
        "id": "oA1C4x3PcnF2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ステートの定義"
      ],
      "metadata": {
        "id": "1MMf8gepdvxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated\n",
        "\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "class State(BaseModel):\n",
        "  query: str = Field(\n",
        "      ..., description=\"Q-ZARからの質問\"\n",
        "  )\n",
        "  current_role: str = Field(\n",
        "      default=\"\", description=\"選定された回答ロール\"\n",
        "  )\n",
        "  messages: Annotated[list[str], operator.add] = Field(\n",
        "      default=[], description=\"回答履歴\"\n",
        "  )\n",
        "  current_judge: bool = Field(\n",
        "      default=False, description=\"品質チェックの結果\"\n",
        "  )\n",
        "  judgement_reason:str=Field(\n",
        "      default=\"\", description=\"品質チェックの判定理由\"\n",
        "  )"
      ],
      "metadata": {
        "id": "NDyphha5dyAF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Chat modelの初期化"
      ],
      "metadata": {
        "id": "TVgJdakRfCpB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import ConfigurableField\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.0)\n",
        "\n",
        "llm = llm.configurable_fields(max_tokens=ConfigurableField(id='max_tokens'))"
      ],
      "metadata": {
        "id": "DeG4yQuxfGT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ノードの定義"
      ],
      "metadata": {
        "id": "Wjv-0FN6f2yr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### selectionノードの実装"
      ],
      "metadata": {
        "id": "4EGcY5j3f_z6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selectionノードの実装\n",
        "from typing import Any\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "def selection_node(state: State)-> dict[str, Any]:\n",
        "  query = state.query\n",
        "  role_options = \"\\n\".join([f\"{k}.{v['name']}:{v['description']}\" for k, v in ROLES.items()])\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"質問を分析し、最も適切な回答担当ロールを選択してください。\n",
        "\n",
        "選択肢:\n",
        "{role_options}\n",
        "\n",
        "回答は選択肢の番号（1、2、または3）のみを返してください。\n",
        "\n",
        "質問:{query}\n",
        "\"\"\".strip()\n",
        "  )\n",
        "  chain = prompt | llm.with_config(configureble=dict(max_tokens=1)) | StrOutputParser()\n",
        "  role_number = chain.invoke({\"role_options\": role_options, \"query\": query})\n",
        "\n",
        "  selected_role = ROLES[role_number.strip()]['name']\n",
        "  return {\"current_role\": selected_role}"
      ],
      "metadata": {
        "id": "WhppTgeEfz2R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### answeringノードの実装"
      ],
      "metadata": {
        "id": "SfrSI0FskC90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from ast import Str\n",
        "def answering_node(state: State)-> dict[str, Any]:\n",
        "  query = state.query\n",
        "  role = state.current_role\n",
        "  role_details = \"\\n\".join([f\"- {v['name']}: {v['details']}\" for v in ROLES.values()])\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"あなたは{role}として回答してください。以下の質問に対して、あなたの役割に基づいた適切な回答を提供してください。\n",
        "\n",
        "役割の詳細:\n",
        "{role_details}\n",
        "\n",
        "質問:{query}\n",
        "\n",
        "回答:\"\"\".strip()\n",
        "  )\n",
        "  chain = prompt | llm | StrOutputParser()\n",
        "  answer = chain.invoke({\"role\": role, \"role_details\": role_details, \"query\": query})\n",
        "  return {\"messages\": [answer]}"
      ],
      "metadata": {
        "id": "Q-gauIIRkGzv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### chackノードの実装"
      ],
      "metadata": {
        "id": "vQ1HgW1gleTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Judgement(BaseModel):\n",
        "  reason: str = Field(default='', description=\"判定理由\")\n",
        "  judge: bool = Field(default=False, description=\"判定結果\")\n",
        "\n",
        "def check_node(state: State)-> dict[str, Any]:\n",
        "  query = state.query\n",
        "  answer = state.messages[-1]\n",
        "  prompt = ChatPromptTemplate.from_template(\n",
        "\"\"\"以下の回答の品質をチェックし、問題がある場合は'False'、問題がない場合は'True'を回答してください。また、その判定理由も説明してください。\n",
        "\n",
        "ユーザーからの質問: {query}\n",
        "回答: {answer}\n",
        "\"\"\".strip()\n",
        "  )\n",
        "  chain = prompt | llm.with_structured_output(Judgement)\n",
        "  result: Judgement = chain.invoke({\"query\": query, \"answer\": answer})\n",
        "\n",
        "  return {\n",
        "      \"current_judge\": result.judge,\n",
        "      \"judgement_reason\": result.reason\n",
        "  }"
      ],
      "metadata": {
        "id": "HY4Yb5WllhHO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グラフの作成"
      ],
      "metadata": {
        "id": "NexH5M6mm95M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph\n",
        "\n",
        "workflow = StateGraph(State)"
      ],
      "metadata": {
        "id": "w9gUuK9Cm_-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ノードの追加"
      ],
      "metadata": {
        "id": "MeKRUoWQncOT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.add_node(\"selection\", selection_node)\n",
        "workflow.add_node(\"answering\", answering_node)\n",
        "workflow.add_node(\"check\", check_node)"
      ],
      "metadata": {
        "id": "_F3XVGc4neas"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### エッジの定義"
      ],
      "metadata": {
        "id": "tidb9zdBnwxB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "workflow.set_entry_point(\"selection\")\n",
        "workflow.add_edge(\"selection\", \"answering\")\n",
        "workflow.add_edge(\"answering\", \"check\")"
      ],
      "metadata": {
        "id": "ISHoEEzany7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 条件付きエッジの定義"
      ],
      "metadata": {
        "id": "OQsLRm8_n8aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import END\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"check\",\n",
        "    lambda state: state.current_judge,\n",
        "    {True: END, False: \"selection\"}\n",
        ")"
      ],
      "metadata": {
        "id": "KOnG_U41n-tt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グラフのコンパイル"
      ],
      "metadata": {
        "id": "CsogMAWSob-X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "compiled = workflow.compile()\n"
      ],
      "metadata": {
        "id": "Sx9euUMBoamj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### グラフの実行"
      ],
      "metadata": {
        "id": "hrjaopcao8JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initial_state = State(query=\"生成AIについて教えてください。\")\n",
        "result = compiled.invoke(initial_state)\n"
      ],
      "metadata": {
        "id": "9IXgrHIBo95d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hz1wyF_mqpJg",
        "outputId": "b9269eaa-bf4d-46e7-d930-5279e2c0220b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'query': '生成AIについて教えてください。', 'current_role': '生成AI製品エキスパート', 'messages': ['生成AI製品エキスパートとしてお答えします。\\n\\n生成AIとは、人工知能の一分野であり、テキスト、画像、音声、動画などのコンテンツを自動的に生成する技術を指します。これには、自然言語処理（NLP）、コンピュータビジョン、音声合成などの技術が含まれます。生成AIの代表的なモデルには、OpenAIのGPTシリーズやDALL-E、GoogleのBERT、DeepMindのAlphaFoldなどがあります。\\n\\n生成AIは、以下のような多くの分野で活用されています。\\n\\n1. **コンテンツ生成**: ブログ記事、ニュース記事、広告コピーなどの自動生成。\\n2. **クリエイティブアート**: 絵画や音楽の生成、デザインの提案。\\n3. **カスタマーサポート**: チャットボットによる自動応答。\\n4. **教育**: 個別学習プランの作成や教材の自動生成。\\n5. **医療**: 診断支援や医療データの解析。\\n\\n生成AIの技術は急速に進化しており、特にディープラーニングの進展により、より自然で人間らしいコンテンツの生成が可能になっています。しかし、倫理的な問題やバイアスのリスクも存在するため、これらの課題に対する対策も重要です。\\n\\n生成AIの未来は非常に明るく、多くの産業での革新を促進する可能性がありますが、同時にその利用には慎重さも求められます。'], 'current_judge': True, 'judgement_reason': '回答は生成AIについての基本的な情報を網羅しており、具体例や活用分野についても詳しく説明されています。また、技術の進化や倫理的な課題についても触れており、バランスの取れた内容です。'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9.4 チェックポイント機能：ステートの永続化と再開"
      ],
      "metadata": {
        "id": "3XMMEYI64lpH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ハンズオン：チェックポイントの動作を確認する"
      ],
      "metadata": {
        "id": "NMdBpQ-L7Pli"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 事前セットアップ"
      ],
      "metadata": {
        "id": "J8vjURJt7_Mt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain==0.3.0 langchain-openai==0.2.0 langgraph==0.2.22 langgraph-checkpoint==1.0.11"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P5xy620k7TCH",
        "outputId": "f462af9b-ac27-4702-f42a-1f989ec05fb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain==0.3.0\n",
            "  Downloading langchain-0.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting langchain-openai==0.2.0\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Collecting langgraph==0.2.22\n",
            "  Downloading langgraph-0.2.22-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting langgraph-checkpoint==1.0.11\n",
            "  Downloading langgraph_checkpoint-1.0.11-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.0.37)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (3.11.11)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (0.3.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (0.3.5)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain==0.3.0)\n",
            "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain==0.3.0) (2.32.3)\n",
            "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain==0.3.0)\n",
            "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai==0.2.0) (1.59.9)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.0)\n",
            "  Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint==1.0.11) (1.1.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.0) (1.18.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (3.10.15)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (0.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.0) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.0) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain==0.3.0) (2024.12.14)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.0) (3.1.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.0) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.0) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain==0.3.0) (3.0.0)\n",
            "Downloading langchain-0.3.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.2.22-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.5/98.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-1.0.11-py3-none-any.whl (17 kB)\n",
            "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
            "Downloading tiktoken-0.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tenacity, tiktoken, langsmith, langgraph-checkpoint, langchain-openai, langgraph, langchain\n",
            "  Attempting uninstall: tenacity\n",
            "    Found existing installation: tenacity 9.0.0\n",
            "    Uninstalling tenacity-9.0.0:\n",
            "      Successfully uninstalled tenacity-9.0.0\n",
            "  Attempting uninstall: langsmith\n",
            "    Found existing installation: langsmith 0.3.2\n",
            "    Uninstalling langsmith-0.3.2:\n",
            "      Successfully uninstalled langsmith-0.3.2\n",
            "  Attempting uninstall: langchain\n",
            "    Found existing installation: langchain 0.3.16\n",
            "    Uninstalling langchain-0.3.16:\n",
            "      Successfully uninstalled langchain-0.3.16\n",
            "Successfully installed langchain-0.3.0 langchain-openai-0.2.0 langgraph-0.2.22 langgraph-checkpoint-1.0.11 langsmith-0.1.147 tenacity-8.5.0 tiktoken-0.8.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get(\"LANGCHAIN_API_KEY\")\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"agent-book\""
      ],
      "metadata": {
        "id": "Y00KFt9g7a71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### グラフのステートとノード関数の定義"
      ],
      "metadata": {
        "id": "lxgIVnMh8Ezl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "from typing import Annotated, Any\n",
        "from langchain_core.messages import SystemMessage, HumanMessage, BaseMessage\n",
        "from langchain_openai import ChatOpenAI\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "class State(BaseModel):\n",
        "  query: str\n",
        "  messages: Annotated[list[BaseMessage], operator.add] = Field(default=[])\n",
        "\n",
        "def add_message(state: State) -> dict[str, Any]:\n",
        "  additional_messages = []\n",
        "  if not state.messages:\n",
        "    additional_messages.append(\n",
        "        SystemMessage(content=\"あなたは最小限の応答をする優秀な対話エージェントです。\")\n",
        "        )\n",
        "  additional_messages.append(HumanMessage(content=state.query))\n",
        "  return {\"messages\": additional_messages}\n",
        "\n",
        "def llm_response(state: State) -> dict[str, Any]:\n",
        "  llm = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0.5)\n",
        "  ai_message = llm.invoke(state.messages)\n",
        "  return {\"messages\": [ai_message]}"
      ],
      "metadata": {
        "id": "QLgwFS3Y8IZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### チェックポイントの内容を表示する関数を定義"
      ],
      "metadata": {
        "id": "QpdUe-EnZAYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "from langchain_core.runnables import RunnableConfig\n",
        "from langgraph.checkpoint.base import BaseCheckpointSaver\n",
        "\n",
        "def print_checkpoint_dump(checkpointer: BaseCheckpointSaver, config: RunnableConfig):\n",
        "  checkpoint_tuple = checkpointer.get_tuple(config)\n",
        "\n",
        "  print(\"チェックポイントデータ：\")\n",
        "  pprint(checkpoint_tuple.checkpoint)\n",
        "  print(\"\\nメタデータ：\")\n",
        "  pprint(checkpoint_tuple.metadata)"
      ],
      "metadata": {
        "id": "Wq2bcNzUZFiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### グラフの定義とコンパイル"
      ],
      "metadata": {
        "id": "7oAIufaaaJCs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langgraph.graph import StateGraph, END\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "\n",
        "graph = StateGraph(State)\n",
        "graph.add_node(\"add_message\", add_message)\n",
        "graph.add_node(\"llm_response\", llm_response)\n",
        "\n",
        "graph.set_entry_point(\"add_message\")\n",
        "graph.add_edge(\"add_message\", \"llm_response\")\n",
        "graph.add_edge(\"llm_response\", END)\n",
        "\n",
        "checkpointer = MemorySaver()\n",
        "\n",
        "compiled_graph = graph.compile(checkpointer=checkpointer)"
      ],
      "metadata": {
        "id": "9ELc7xSBaMeV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 実行して動作を確認する"
      ],
      "metadata": {
        "id": "quzX38u8b1US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"example-1\"}}\n",
        "user_query = State(query=\"私の好きなものはずんだ餅です。覚えておいてね。\")\n",
        "first_response = compiled_graph.invoke(user_query, config)\n",
        "first_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZENTlQuRb5s0",
        "outputId": "415b1c9e-ed1f-4214-ac6d-25ab9160bc01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '私の好きなものはずんだ餅です。覚えておいてね。',\n",
              " 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})]}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for checkpoint in checkpointer.list(config):\n",
        "  print(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PoBXh7TchRm",
        "outputId": "9fe95ca0-4e26-4d60-8778-ae0f7b9c6865"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-d16f-65e2-8002-d0bc802f4d41'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:46.101839+00:00', 'id': '1efe4672-d16f-65e2-8002-d0bc802f4d41', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})], 'llm_response': 'llm_response'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000004.0.8921788420789459', 'start:add_message': '00000000000000000000000000000003.0.8401082468070012', 'add_message': '00000000000000000000000000000004.0.08831315194332956', 'llm_response': '00000000000000000000000000000004.0.3020413261133359'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.8990439193081792'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'llm_response': {'messages': [AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c291-6243-8001-23a313f67860'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c291-6243-8001-23a313f67860'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:44.542804+00:00', 'id': '1efe4672-c291-6243-8001-23a313f67860', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})], 'add_message': 'add_message'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000003.0.5767511294256943', 'start:add_message': '00000000000000000000000000000003.0.8401082468070012', 'add_message': '00000000000000000000000000000003.0.8990439193081792'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'add_message': {'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c288-6c69-8000-eba18b801418'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c288-6c69-8000-eba18b801418'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:44.539370+00:00', 'id': '1efe4672-c288-6c69-8000-eba18b801418', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [], 'start:add_message': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000002.0.9564266352947441', 'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c27f-67a4-bfff-5f8c1c003071'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c27f-67a4-bfff-5f8c1c003071'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:44.535576+00:00', 'id': '1efe4672-c27f-67a4-bfff-5f8c1c003071', 'channel_values': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}, 'channel_versions': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_checkpoint_dump(checkpointer, config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfBgFw3WdInB",
        "outputId": "0c708c6c-2993-40c5-aeb8-1abdde279295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "チェックポイントデータ：\n",
            "{'channel_values': {'llm_response': 'llm_response',\n",
            "                    'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
            "                                 HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
            "                                 AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})],\n",
            "                    'query': '私の好きなものはずんだ餅です。覚えておいてね。'},\n",
            " 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391',\n",
            "                      'add_message': '00000000000000000000000000000004.0.08831315194332956',\n",
            "                      'llm_response': '00000000000000000000000000000004.0.3020413261133359',\n",
            "                      'messages': '00000000000000000000000000000004.0.8921788420789459',\n",
            "                      'query': '00000000000000000000000000000002.0.43975545580576436',\n",
            "                      'start:add_message': '00000000000000000000000000000003.0.8401082468070012'},\n",
            " 'id': '1efe4672-d16f-65e2-8002-d0bc802f4d41',\n",
            " 'pending_sends': [],\n",
            " 'ts': '2025-02-06T08:48:46.101839+00:00',\n",
            " 'v': 1,\n",
            " 'versions_seen': {'__input__': {},\n",
            "                   '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'},\n",
            "                   'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'},\n",
            "                   'llm_response': {'add_message': '00000000000000000000000000000003.0.8990439193081792'}}}\n",
            "\n",
            "メタデータ：\n",
            "{'parents': {},\n",
            " 'source': 'loop',\n",
            " 'step': 2,\n",
            " 'writes': {'llm_response': {'messages': [AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})]}}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_query = State(query=\"私の好物はなにか覚えている？\")\n",
        "second_response = compiled_graph.invoke(user_query, config)\n",
        "second_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvnsHaD-dXnc",
        "outputId": "0dbf4091-4550-42e7-98e2-e20338448c69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '私の好物はなにか覚えている？',\n",
              " 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65}),\n",
              "  HumanMessage(content='私の好物はなにか覚えている？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='はい、ずんだ餅ですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-db9f2c2f-e550-4b9e-8fcd-cc8ce4e66091-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for checkpoint in checkpointer.list(config):\n",
        "  print(checkpoint)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C5iAl4Smd9Lq",
        "outputId": "03b9ac0e-0b63-48b8-e103-b55b2637704a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-f352-6173-8006-9c922de4e21f'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:53:44.933998+00:00', 'id': '1efe467d-f352-6173-8006-9c922de4e21f', 'channel_values': {'query': '私の好物はなにか覚えている？', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65}), HumanMessage(content='私の好物はなにか覚えている？', additional_kwargs={}, response_metadata={}), AIMessage(content='はい、ずんだ餅ですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-db9f2c2f-e550-4b9e-8fcd-cc8ce4e66091-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})], 'llm_response': 'llm_response'}, 'channel_versions': {'__start__': '00000000000000000000000000000006.0.003889563998099921', 'query': '00000000000000000000000000000006.0.4290179671457751', 'messages': '00000000000000000000000000000008.0.7785246918770106', 'start:add_message': '00000000000000000000000000000007.0.4539475923696069', 'add_message': '00000000000000000000000000000008.0.5149971698413672', 'llm_response': '00000000000000000000000000000008.0.12931788075266215'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.8306384583598798'}, 'add_message': {'start:add_message': '00000000000000000000000000000006.0.32953331626290017'}, 'llm_response': {'add_message': '00000000000000000000000000000007.0.1897659524781642'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'llm_response': {'messages': [AIMessage(content='はい、ずんだ餅ですね。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 84, 'total_tokens': 94, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-db9f2c2f-e550-4b9e-8fcd-cc8ce4e66091-0', usage_metadata={'input_tokens': 84, 'output_tokens': 10, 'total_tokens': 94})]}}, 'step': 6, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-ea95-6e4c-8005-0a1ad70117b0'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-ea95-6e4c-8005-0a1ad70117b0'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:53:44.018053+00:00', 'id': '1efe467d-ea95-6e4c-8005-0a1ad70117b0', 'channel_values': {'query': '私の好物はなにか覚えている？', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65}), HumanMessage(content='私の好物はなにか覚えている？', additional_kwargs={}, response_metadata={})], 'add_message': 'add_message'}, 'channel_versions': {'__start__': '00000000000000000000000000000006.0.003889563998099921', 'query': '00000000000000000000000000000006.0.4290179671457751', 'messages': '00000000000000000000000000000007.0.9488153417945379', 'start:add_message': '00000000000000000000000000000007.0.4539475923696069', 'add_message': '00000000000000000000000000000007.0.1897659524781642', 'llm_response': '00000000000000000000000000000005.0.5498645998390022'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.8306384583598798'}, 'add_message': {'start:add_message': '00000000000000000000000000000006.0.32953331626290017'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.8990439193081792'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'add_message': {'messages': [HumanMessage(content='私の好物はなにか覚えている？', additional_kwargs={}, response_metadata={})]}}, 'step': 5, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-ea8e-625b-8004-00ab2f653d9a'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-ea8e-625b-8004-00ab2f653d9a'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:53:44.014875+00:00', 'id': '1efe467d-ea8e-625b-8004-00ab2f653d9a', 'channel_values': {'query': '私の好物はなにか覚えている？', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})], 'start:add_message': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000006.0.003889563998099921', 'query': '00000000000000000000000000000006.0.4290179671457751', 'messages': '00000000000000000000000000000006.0.3583190793077148', 'start:add_message': '00000000000000000000000000000006.0.32953331626290017', 'add_message': '00000000000000000000000000000004.0.08831315194332956', 'llm_response': '00000000000000000000000000000005.0.5498645998390022'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000005.0.8306384583598798'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.8990439193081792'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 4, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-ea84-6dc3-8003-bad89cbd8948'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe467d-ea84-6dc3-8003-bad89cbd8948'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:53:44.011039+00:00', 'id': '1efe467d-ea84-6dc3-8003-bad89cbd8948', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})], '__start__': State(query='私の好物はなにか覚えている？', messages=[])}, 'channel_versions': {'__start__': '00000000000000000000000000000005.0.8306384583598798', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000004.0.8921788420789459', 'start:add_message': '00000000000000000000000000000003.0.8401082468070012', 'add_message': '00000000000000000000000000000004.0.08831315194332956', 'llm_response': '00000000000000000000000000000005.0.5498645998390022'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.8990439193081792'}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': State(query='私の好物はなにか覚えている？', messages=[])}, 'step': 3, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-d16f-65e2-8002-d0bc802f4d41'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-d16f-65e2-8002-d0bc802f4d41'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:46.101839+00:00', 'id': '1efe4672-d16f-65e2-8002-d0bc802f4d41', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={}), AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})], 'llm_response': 'llm_response'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000004.0.8921788420789459', 'start:add_message': '00000000000000000000000000000003.0.8401082468070012', 'add_message': '00000000000000000000000000000004.0.08831315194332956', 'llm_response': '00000000000000000000000000000004.0.3020413261133359'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}, 'llm_response': {'add_message': '00000000000000000000000000000003.0.8990439193081792'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'llm_response': {'messages': [AIMessage(content='ずんだ餅ですね！覚えておきます。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 14, 'prompt_tokens': 51, 'total_tokens': 65, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_72ed7ab54c', 'finish_reason': 'stop', 'logprobs': None}, id='run-60294ad7-eba7-4cb0-917e-d4bf4afb0f0c-0', usage_metadata={'input_tokens': 51, 'output_tokens': 14, 'total_tokens': 65})]}}, 'step': 2, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c291-6243-8001-23a313f67860'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c291-6243-8001-23a313f67860'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:44.542804+00:00', 'id': '1efe4672-c291-6243-8001-23a313f67860', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})], 'add_message': 'add_message'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000003.0.5767511294256943', 'start:add_message': '00000000000000000000000000000003.0.8401082468070012', 'add_message': '00000000000000000000000000000003.0.8990439193081792'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'add_message': {'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': {'add_message': {'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}), HumanMessage(content='私の好きなものはずんだ餅です。覚えておいてね。', additional_kwargs={}, response_metadata={})]}}, 'step': 1, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c288-6c69-8000-eba18b801418'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c288-6c69-8000-eba18b801418'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:44.539370+00:00', 'id': '1efe4672-c288-6c69-8000-eba18b801418', 'channel_values': {'query': '私の好きなものはずんだ餅です。覚えておいてね。', 'messages': [], 'start:add_message': '__start__'}, 'channel_versions': {'__start__': '00000000000000000000000000000002.0.9427873896729391', 'query': '00000000000000000000000000000002.0.43975545580576436', 'messages': '00000000000000000000000000000002.0.9564266352947441', 'start:add_message': '00000000000000000000000000000002.0.20357570862043772'}, 'versions_seen': {'__input__': {}, '__start__': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}}, 'pending_sends': []}, metadata={'source': 'loop', 'writes': None, 'step': 0, 'parents': {}}, parent_config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c27f-67a4-bfff-5f8c1c003071'}}, pending_writes=[])\n",
            "CheckpointTuple(config={'configurable': {'thread_id': 'example-1', 'checkpoint_ns': '', 'checkpoint_id': '1efe4672-c27f-67a4-bfff-5f8c1c003071'}}, checkpoint={'v': 1, 'ts': '2025-02-06T08:48:44.535576+00:00', 'id': '1efe4672-c27f-67a4-bfff-5f8c1c003071', 'channel_values': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}, 'channel_versions': {'__start__': '00000000000000000000000000000001.0.024215387517839138'}, 'versions_seen': {'__input__': {}}, 'pending_sends': []}, metadata={'source': 'input', 'writes': {'__start__': State(query='私の好きなものはずんだ餅です。覚えておいてね。', messages=[])}, 'step': -1, 'parents': {}}, parent_config=None, pending_writes=[])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = {\"configurable\": {\"thread_id\": \"example-2\"}}\n",
        "user_query = State(query=\"私の好物は何？\")\n",
        "other_thread_response = compiled_graph.invoke(user_query, config)\n",
        "other_thread_response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHzNClv2elxX",
        "outputId": "27f9ea1c-71d8-4ac3-e15a-371aae4e9b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': '私の好物は何？',\n",
              " 'messages': [SystemMessage(content='あなたは最小限の応答をする優秀な対話エージェントです。', additional_kwargs={}, response_metadata={}),\n",
              "  HumanMessage(content='私の好物は何？', additional_kwargs={}, response_metadata={}),\n",
              "  AIMessage(content='わかりませんが、あなたの好物について教えていただければ嬉しいです。', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 39, 'total_tokens': 60, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-0a1b06af-fcd0-4643-a8f8-78020ff780f4-0', usage_metadata={'input_tokens': 39, 'output_tokens': 21, 'total_tokens': 60})]}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}